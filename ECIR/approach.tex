\section{Relationship Prediction Approach}

Given a DHIN graph $G=(V,E)$, and the number of graph snapshots $t$, we first decompose $G$ to a sequence of $t$ HIN graphs ${G_1, .., G_t}$ based on links with associated timestamps. We then apply our techniques to predict $G_{t+1}$. As mentioned in Definition \ref{problemdef}, in this work we intend to predict \textit{existence of a given type of relationship} (target meta path) between two given nodes. Therefore we define a new type of graph, called \textit{augmented reduced graph}, that is generated based on a given heterogeneous graph and a target relation meta path. 

\begin{definition}[Augmented reduced graph]\label{def:ARG}
Given a HIN graph $G=(V,E)$ and a target meta path $P(A_i,A_j)$ between nodes of type $A_i$ and $A_j$, an \textit{augmented reduced graph} $G^P=(V^P,E^P)$ is a graph, where $V^P \subseteq V$ and nodes in $V^P$ are of type $A_i$ and $A_j$, and edges in $E^P$ indicates relationships of type $P$ in $G$. $\Box$
\end{definition}

%\begin{example}
An augmented reduced graph for the network in Figure \ref{sampleNetwork} and target meta path $P(A,A)$=\textit{A--P--V--P--A} is a graph with nodes of type \textit{Author} and edges that represent relationship of \textit{publishing in the same venue}. For example (\textit{Max}, \textit{Ada}) is an edge in the corresponding augmented reduced graph because they both published at KDD and ICDM. If we consider meta path $P(A,A)$=\textit{A--P--A}, the augmented reduced graph represents a co-authorship graph, where nodes are of type \textit{Author} and edges, such as (\textit{Max}, \textit{Tom}), represent \textit{co-authorship}.  
%$\Box$
%\end{example}


%\subsection{Algorithm}

\subsection{Homogenize link prediction}
% We refer to this approach as \texttt{HomoTemp}.

Zhu et al. \cite{Zhu2016} studied the problem of temporal link prediction in the context of homogeneous networks, where the input is a sequence of graphs $G_1, ..., G_t$ and the output is the estimated $G_{t+1}$. The authors presented a matrix factorization (MF) with block-coordinate gradient descent technique that for each $G_\tau$ at time $\tau$ infers a low rank $k$-dimensional latent space representation matrix $Z_\tau$ that minimizes the quadratic loss with temporal regularization
\begin{equation}\label{latentOrigEqu}
    \begin{array}{l}
\argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
\\
\text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
    \end{array}
\end{equation}
where $\lambda$ is a regularization parameter, and  $(1-Z_{\tau}(u)Z_{\tau-1}(u)^T)$ penalizes node $u$ for suddenly changing its latent position. %Note that when computing the quadratic loss $\left \| G^R_\tau-Z_{\tau}BZ_{\tau}^T \right \|^2_F$, we ignore all of the diagonal entries.
$Z_\tau(u)$ is a row vector denoting $u$'s temporal latent space representation at time $\tau$, and $Z_\tau(u,i)$ indicates the position of $u$ in the $i$-th dimension at $Z$. The intuition behind their prediction model is that 1) nodes move smoothly in the latent space over time and it is less likely to have large moves \cite{sarkar2005dynamic,zhang2014inferring}, and 2) user interactions are more likely to occur between similar users in a latent space representation. The authors used $Z_tZ_t^T$ to predict $G_{t+1}$ in their work, however, they mentioned that $G_{t+1}$ can be formulated as $\Phi(f(Z_1,...Z_t))$, where $\Phi$ is the link function and $f$ is the temporal function and one may apply techniques such as nonparametric approaches \cite{Sarkar:2012} to automatically learn these functions.

An immediate adaptation of the above MF technique is to consider a sequence of augmented reduced graphs $G^P_i$ as input, i.e., graphs with source and destination of a target meta path with edges between them if the target meta path exists in $G_i$. This changes equation (\ref{latentOrigEqu}) by replacing $G_\tau$ with $G^{P}_\tau$.


%to the following
%\begin{equation}\label{latentReducedEqu}
%    \begin{array}{l}
%\argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G^{P}_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
%\\
%\text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
%    \end{array}
%\end{equation}

%Their MF technique \cite{Zhu2016} to infer $Z_t$ and estimate $G_{t+1}^R$. We refer to this approach as \texttt{HomoTemp}.


Algorithm \ref{alg1} gets as an input a DHIN graph $G$, number of graph snapshots $t$, a target relation meta path $P(a,b)$, and latent space dimension $k$. The algorithm first decomposes $G$ into a sequence of graphs $\{G_1, .., G_t\}$ (line 1) by considering the associated timestamps on edges. Next from each graph snapshot $G_i$, a corresponding augmented reduced graph $G^P_i$ is generated (lines 2-8) for which nodes are of type $a$ and $b$ (beginning and end of target relation meta path $P$). Finally the MF technique in \cite{Zhu2016} is applied (lines 9-10) to infer $k$-dimensional temporal latent spaces $Z_1, ...,Z_t$ and estimate $G^P_{t+1}$ by $Z_tZ_t^T$.
\amin{How $Z_{t+1}$ depends on $Z_1, ..., Z_t$ from the algorithm? Explain assumptions in \cite{Zhu2016}.}


\begin{algorithm}[t]
\caption{Homogenize Link Prediction}\label{alg1}
\begin{algorithmic}[1]\scriptsize
\REQUIRE A DHIN graph $G$, number of graph snapshots $t$, a target relation meta path $P(a,b)$, latent space dimension $k$
\ENSURE The predicted graph $G^P$ at time $t+1$ based on the given target relation meta path $P$

\STATE $\{G_1, .., G_t\} \leftarrow DecomposeGraph(G, t)$

\FOR {each graph $G_i$}
    %\STATE $G^R_i \leftarrow AugmentedReducedGraph(G_i,P,S)$
    \STATE Let $a$ and $b$ be the node types of beginning and end of $P$
    
    %\FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
    \FOR {each node $x \in V_i$ of type $a$ in $G_i$}
        \STATE follow $P$ to reach a node $y$ of type $b$ in $G_i$ 
        \STATE add edge $(x,y)$ to augmented reduced graph $G_i^P$ 
\ENDFOR

\ENDFOR
%\STATE $G^R_{t+1} \leftarrow MF(G^R,k)$ \cite{Zhu2016}
\STATE Infer temporal latent spaces $Z_1, .., Z_t$ using \textit{MF}%by optimizing Eq. \ref{latentReducedEqu}

\STATE $G^P_{t+1} \leftarrow Z_tZ^T_t$ 

\STATE return $G^P_{t+1}$
\end{algorithmic}
\end{algorithm}



\subsection{Meta path-based relationship prediction}

The homogenize approach, however, does not consider different semantics of meta paths between the source and destination nodes. In fact, Zhu et al. \cite{Zhu2016} assume that the probability of a link between nodes depends only on their latent positions. However, we also consider meta path-based features in our prediction model. Our intuition is that leveraging meta path-based features \cite{sun2011pathsim} helps to boost prediction accuracy besides using latent space feature space. In other word, we combine latent space features with topological meta path-based features.

We define a set of meta paths \cite{sun2011pathsim} on a given network schema and a target relation meta path $P$, such as co-authorship, to generate an augmented reduced graph (Definition \ref{def:ARG}) $G^P_i$ from $G_i$ based on $P$.  We then leverage the technique in \cite{Zhu2016} to predict $G^P_{t+1}$ given $G^P_1, ..., G^P_t$, by inferring the temporal latent space representation for nodes at time $t+1$.\amin{this para seems wrong!!!}

Algorithm \ref{alg2} gets as an input a DHIN graph $G$, number of graph snapshots $t$, a network schema $S$, target relation meta path $P(a,b)$ between node types $a$ and $b$, maximum length of a meta path $l$, and latent space dimension $k$. Same as Algorithm \ref{alg1}, it decomposes $G$ into a sequence of graphs (line 1). It then produces the set of all meta paths between a node type $a$ and type $b$ defined in the given target relation $P(a,b)$ (line 2). This is done by traversing the network schema $S$ (for instance through a BFS traversal) and generating meta paths with maximum length of $l$ .

\begin{algorithm}[t]
\caption{Meta path-based Link Prediction}\label{alg2}
\begin{algorithmic}[1]\scriptsize
\REQUIRE A dynamic heterogeneous graph $G$, number of graph snapshots $t$, network schema $S$, a target relation meta path $P^*(a,b)$, maximum length of a meta path $l$, latent space dimension $k$
\ENSURE The predicted graph $G^{P^*}$ at time $t+1$ based on the given target relation $P^*$

\STATE $\{G_1, .., G_t\} \leftarrow DecomposeGraph(G, t)$

\STATE $\{P_1, .., P_n\} \leftarrow GenerateMetaPaths(S, P^*(a,b), l)$

\FOR {each meta path $P_j(a,b)$}

\FOR {each graph $G_i$}
    %\STATE $G^R_i \leftarrow AugmentedReducedGraph(G_i,R,S)$
    %\STATE Let $a$ and $b$ be the node types of beginning and end of $P_j$
    
    %\FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
    \FOR {each node $x \in V_i$ of type $a$ in $G_i$}
        \STATE follow $P_j$ to reach a node $y$ of type $b$ in $G_i$ 
        \STATE $w_{xy} \leftarrow MeasureSimilarity(x,y, G_i)$
        \STATE add edge $(x,y)$ with weight $w_{xy}$ to augmented reduced graph $G_i^{P_j}$ 
\ENDFOR

\ENDFOR

%\STATE $G^R_{t+1} \leftarrow MF(G^R,k)$ \cite{Zhu2016}
\STATE Infer temporal latent spaces $Z_1, .., Z_t$ using \textit{MF}%by optimizing Eq. \ref{latentReducedEqu}
\STATE $G^{P_j}_{t+1} \leftarrow Z_tZ^T_t$ 

\ENDFOR

\STATE $G^{P^*}_{t} \leftarrow LastKnownTargetGraph(G, P^*(a,b), t)$


\STATE $\forall (a,b\in N(a)) \in G^{P^*}_{t}$, add a feature vector to the training set with $w_{ab}$ in $G^{P_j}_{t-1}$ for each meta paths $P_j$, and label with 1 if $(a,b) \in E^{P^*}_{t}$ otherwise 0.

\STATE Learn the model and apply it to the feature vector of $G^{P_j}_{t+1}$ with different meta path $P_j$.

\STATE Build $G^{P^*}_{t+1}$ based on the cut-off values for the output of prediction model.

\STATE return $G^{P^*}_{t+1}$
\end{algorithmic}
\end{algorithm}


 Next from each graph snapshot $G_i$, a corresponding augmented reduced graph $G^P_i$ is generated (lines 3-9) for which nodes are of type $a$ and $b$ (beginning and end of meta path $P$) and edges have weight between 0 and 1, based on a similarity measure. For example PathCount\cite{sun2011pathsim}, PathSim \cite{sun2011pathsim}, or random walk are measures for the relation of two nodes given link type and meta path, such as co-authorship.
\amin{Note that values of $G^P_i$ depends on meta-path $P$}. Once the sequence of augmented reduced graphs \{$G^P_1, ..., G^P_t$\} are generated, we apply the matrix factorization with the MF technique \cite{Zhu2016} to find a low rank $k$-dimensional latent space representation matrix $Z_\tau$ for nodes at time $\tau$.

% \begin{equation}\label{latentEqu}
%     \begin{array}{l}
% \argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G^{R_i}_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
% \\
% \text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
%     \end{array}
% \end{equation}




%* Restrict pathSim to 3-hops and not beyond

\subsubsection{The predictive model.} Given the training pairs of nodes and their corresponding meta path-based features (similarity weights $w$), we build a prediction model to learn the weights associated with these features by apply logistic regression. We define the probability of existence of a link between nodes $a$ and $b$ as 
$Pr(label = 1|a, b; \boldsymbol{\theta}) = \frac{e^{z}}{e^{z}+1}$
where $z=\sum\limits_{i=1}^{n}\theta_i.w_i$ for $n$ meta paths, and $\theta_i$ is a normalized weight value for $w_i$ (meta path-based feature). We use logistic regression with $L_2$ regularization to estimate the optimal $\theta$. 
%$\boldsymbol{\hat{\theta}} = 
%\operatorname*{arg\,max}_{\boldsymbol{\theta}}\sum_i log Pr(y_i = 1|a_i, b_i; \boldsymbol{\theta}) - \alpha \sum_{j=1}^N \theta_j^2
%$

\begin{equation*}
\boldsymbol{\hat{\theta}} = 
\operatorname*{arg\,max}_{\boldsymbol{\theta}}\sum_i log Pr(y_i = 1|a_i, b_i; \boldsymbol{\theta}) - \alpha \sum_{j=1}^N \theta_j^2
\end{equation*}

We derive \textbf{$\hat{\theta}$} which maximizes the likelihood of all the training pairs, using maximum likelihood estimation.


In the training phase, for each pair of nodes $(a,b)$ in $G^{P^*}_{t}$, where $b \in N(a)$, we add a feature vector to the training set with corresponding $w_{ab}$ in $G^{P_j}_{t-1}$ for each meta paths $P_j$, and with label 1 if $(a,b) \in E^{P^*}_{t}$ otherwise label 0. We then perform logestic regression to learn the model. Finally we apply the model to the feature vector of predicted graphs $G^{P_j}_{t+1}$ with different meta path $P_j$. Finally it builds $G^{P^*}_{t+1}$ based on the cut-off values for the output of prediction model.


\subsection{Combining latent and meta path-based features}

\amin{ISSUES TO DISCUSS}

Zhu et al. \cite{Zhu2016} studied the problem of temporal link prediction in the context of homogeneous networks, where the input is a sequence of graphs $G_1, ..., G_t$ and the output is the estimated $G_{t+1}$. The authors presented a matrix factorization with block-coordinate gradient descent (MF) 


Although the gradient descent algorithm used in the MF technique to infer latent space matrices is fast, we cannot apply it to meta paths efficiently since computing meta path values for all pairs is not scalable. Thus we restrict it to those links that make new connections in future or negative samples and use logistic regression. 

- After $p$-value analysis some latent features might be correlated with meta paths. Removing may increase the accuracy or we can remove those with lower $p$-value. This needs careful analysis as it might be dependent to number of intervals or the size of latent feature.

- $G_{ij} \approx  \sum_{l=1}^{m} \theta_l w_l(i,j) + \sum_{l=1}^{k} \theta_l Z_{il}Z_{jl}$

$ \argmin\limits_{Z} \sum\limits_{(i,j)\in O} \left \| G_\tau(i,j) - \Phi(z_{i}^Tz_{j} + f_D(z_{i,j};w) \right \|^2_F $


- Augmenting latent with explicit features helps to combine latent features with the results of any other link prediction model. Suppose scores $w_{ij}$ is the meta path feature between nodes $i$ and $j$. Then, we can treat this as being a dyadic feature $z_ij$ in the above framework, and learn latent features that fit the residual of these scores. In general then, the latent feature approach has a natural mechanism by which any predictive signal can be incorporated, whether it is an explicit feature vector or model predictions. However, a caveat is in order: it is not necessary that combining latent features with another model will improve performance on test data. If the latent features learn similar structure to the other model, then combining the two cannot be expected to yield better results.

As a final remark, we note that the linear combination of latent and explicit features is not the only way to incorporate side information. This issue has been studied in the context of the cold-start problem [29] in collaborative filtering. Recent advances in this literature are based on inferring reasonable values of latent features by falling back to the side information as a prior [2,12]. However, unlike most collaborative filtering applications, in link prediction we are mostly interested in using side information to improve predictions, rather than dealing with cold-start nodes. Therefore, we expect it to be most useful to directly augment the latent feature prediction with one based on side information.


\subsection{Implementation}

We use the implementation of temporal latent space inference for a sequence of dynamic graph snapshots \footnote{\url{https://github.com/linhongseba/Temporal-Network-Embedding}}\cite{Zhu2016}.
% Self note: The hetrec-2011 dataset (MovieLense-IMDB) have missing user and movie ids as they only consider users with both rating and tags, thus we assign new ids to be able to use the TKDE code.
 For the classification part, we use the efficient LIBLINEAR \cite{fan2008liblinear} package\footnote{\url{https://github.com/cjlin1/liblinear}} and set the type of solver to L2-regularized logistic regression (primal). %that solves $min_w w^Tw/2 + C \sum log(1 + exp(-y_i w^Tx_i))$, where $w$ is the generated weight vector as the model for a given set of instance-label pairs $(x_i, y_i)$, $i$ = 1, . . . , l, $x_i \in R^n$, $y_i \in \{-1, +1\}$,  $w^Tw/2$ is the regularization term, and $C > 0$ is a penalty parameter. In the testing phase, we predict a data point $x$ as positive if $w^Tx > 0$, and negative otherwise.
We performed 5-fold cross validation for the training phase.



% https://arxiv.org/pdf/1803.00744.pdf

%We perform leave-one-patient-out testing, where all data belonging to a single patient are left out in a particular test fold. All hyper-parameters were chosen through a nested cross-validation performed on the training data alone. We used the area under the ROC curve (AUROC) metric to evaluate our classifiers. We use the method presented by DeLong et al. [27] to compute 95\% confidence intervals and to perform statistical significance tests to compare competing prediction methods (significance level was set at 5\%). All reported p values are based on a two-sided z-test.

%[27] DeLong, E.R., DeLong, D.M., Clarke-Pearson, D.L.: Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach. Biometrics (1988) 837?845






% \begin{algorithm}[h]
% \caption{Generate Predicted Graph}\label{alg1}
% \begin{algorithmic}[1]
% \REQUIRE A dynamic heterogeneous graph $G$, number of graph snapshots $t$, network schema $S$, target relation $R(a,b)$ between nodes of type $a$ and $b$, maximum length of a meta path $l$, latent space dimension $k$
% \ENSURE The predicted graph $G^R$ at time $t+1$ based on the given target relation $R$

% \STATE $\{G_1, .., G_t\} \leftarrow DecomposeGraph(G, t)$

% \STATE $\{P_1, .., P_n\} \leftarrow GenerateMetaPaths(S,R,l)$

% \FOR {each heterogeneous graph $G_i$}
%     %\STATE $G^R_i \leftarrow AugmentedReducedGraph(G_i,R,S)$
    
%     \FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
%     \FOR {each node $i$ of type $a$ in $G$}
%         \STATE follow $p$ to reach a node $j$ of type $b$ in $G$ 
%         \STATE $w_{ij} \leftarrow PathSim(i,j)$
%         \STATE add edge $(i,j)$ to graph $G^R$ with weight $w_{ij}$
%     \ENDFOR
% \ENDFOR

    
% \ENDFOR
% %\STATE $G^R_{t+1} \leftarrow MF(G^R,k)$ \cite{Zhu2016}
% \STATE Infer temporal latent spaces $Z_1, .., Z_t$ by optimizing Eq. \ref{latentEqu}

% \STATE $G^R_{t+1} \leftarrow Z_tZ^T_t$ 

% \STATE return $G^R_{t+1}$
% \end{algorithmic}
% \end{algorithm}


%The process of creating an augmented reduced graph is presented in Algorithm \ref{alg2}.

% \begin{algorithm}[h]
% \caption{Generate augmented reduced graph}\label{alg2}
% \begin{algorithmic}[1]
% \REQUIRE A heterogeneous graph $G$, target relation $R(a,b)$ between nodes of type $a$ and $b$, network schema $S$
% \ENSURE An augmented reduced graph $G^R$ based on the given target relation $R$

% \FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
%     \FOR {each node $i$ of type $a$ in $G$}
%         \STATE follow $p$ to reach a node $j$ of type $b$ in $G$ 
%         \STATE $w_{ij} \leftarrow PathSim(i,j)$
%         \STATE add edge $(i,j)$ to graph $G^R$ with weight $w_{ij}$
%     \ENDFOR
% \ENDFOR

% \STATE return $G^R$
% \end{algorithmic}
% \end{algorithm}