\section{Relationship Prediction Approach}

Given a DHIN graph $G=(V,E)$, and the number of graph snapshots $t$, we first decompose $G$ to a sequence of $t$ HIN graphs ${G_1, .., G_t}$ based on links with associated timestamps. We then apply our techniques to predict $G_{t+1}$. As mentioned in Definition \ref{problemdef}, in this work we intend to predict \textit{existence of a given type of relationship} (target meta path) between two given nodes. Therefore we define a new type of graph, called \textit{augmented reduced graph}, that is generated based on a given heterogeneous graph and a target relation meta path. 

\begin{definition}[Augmented reduced graph]\label{def:ARG}
Given a HIN graph $G=(V,E)$ and a target meta path $P(A_i,A_j)$ between nodes of type $A_i$ and $A_j$, an \textit{augmented reduced graph} $G^P=(V^P,E^P)$ is a weighted graph, where $V^P \subseteq V$ and nodes in $V^P$ are of type $A_i$ and $A_j$, edges in $E^P$ indicates relationships of type $P$ in $G$, and each edge $e^P = (u, v, w)$ is a weighted edge from a vertex $u$ to a vertex $v$ with a weight $w=Sim(u,v)$ indicating a similarity measure between $u$ and $v$. $\Box$
\end{definition}

%\begin{example}

Examples of relation similarity measure between two nodes in a HIN are path count \cite{sun2011pathsim,sun2011ASONAM}, PathSim \cite{sun2011pathsim} or normalized path count \cite{sun2011ASONAM}, random walk and symmetric random walk \cite{sun2011ASONAM}, and HeteSim \cite{shi2014hetesim}. Path count measures the number of path instances between the source and target nodes of a given meta path, and can be calculated by multiplying adjacency matrices of relations in the meta path \cite{sun2011ASONAM}. Random walk measures the probability of the random walk from source to target nodes. HeteSim evaluates relevance of heterogeneous nodes given an arbitrary path, while PathSim[5] evaluate similarity of same-typed nodes based on a symmetric path.

An augmented reduced graph for the network in Figure \ref{sampleNetwork} and target meta path $P(A,A)$=\textit{A--P--V--P--A} is a graph with nodes of type \textit{Author} and edges that represent relationship of \textit{publishing in the same venue}. For example (\textit{Max}, \textit{Ada}) is an edge in the corresponding augmented reduced graph because they both published at KDD and ICDM. If we consider meta path $P(A,A)$=\textit{A--P--A}, the augmented reduced graph represents a co-authorship graph, where nodes are of type \textit{Author} and edges, such as (\textit{Max}, \textit{Tom}), represent \textit{co-authorship}.  
%$\Box$
%\end{example}



%\subsection{Algorithm}

\subsection{Homogenize link prediction}
% We refer to this approach as \texttt{HomoTemp}.

Zhu et al. \cite{Zhu2016} studied the problem of temporal link prediction in the context of homogeneous networks, where the input is a sequence of graphs $G_1, ..., G_t$ and the output is the estimated $G_{t+1}$. They present a matrix factorization (MF) with block-coordinate gradient descent technique that for each adjacency matrix $G_\tau$ at time $\tau$ infers a low rank $k$-dimensional latent space representation matrix $Z_\tau$ that minimizes %the quadratic loss with temporal regularization
\begin{equation}\label{latentOrigEqu}
    \begin{array}{l}
\argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
\\
\text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
    \end{array}
\end{equation}
where $\lambda$ is a regularization parameter, and  $(1-Z_{\tau}(u)Z_{\tau-1}(u)^T)$ penalizes node $u$ for suddenly changing its latent position. %Note that when computing the quadratic loss $\left \| G^R_\tau-Z_{\tau}BZ_{\tau}^T \right \|^2_F$, we ignore all of the diagonal entries.
$Z_\tau(u)$ is a row vector denoting $u$'s temporal latent space representation at time $\tau$, and $Z_\tau(u,i)$ indicates the position of $u$ in the $i$-th dimension at $Z$. The intuition behind their prediction model is that 1) nodes move smoothly in the latent space over time and it is less likely to have large moves \cite{sarkar2005dynamic,zhang2014inferring}, and 2) user interactions are more likely to occur between similar users in a latent space representation. To predict adjacency matrix $G_{t+1}$ they used $Z_tZ_t^T$, however, they mentioned that $G_{t+1}$ can be formulated as $\Phi(f(Z_1,...Z_t))$, where $\Phi$ and $f$ are the link and the temporal functions that one may apply techniques such as nonparametric approaches \cite{Sarkar:2012} to learn them.

Algorithm \ref{alg1} is an adaptation of the above MF technique applied on a sequence of augmented reduced graphs $G^P_i$ (Definition \ref{def:ARG}) given a target meta path $P$, which changes equation (\ref{latentOrigEqu}) by replacing $G_\tau$ with $G^{P}_\tau$.
%to the following
%\begin{equation}\label{latentReducedEqu}
%    \begin{array}{l}
%\argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G^{P}_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
%\\
%\text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
%    \end{array}
%\end{equation}
%Their MF technique \cite{Zhu2016} to infer $Z_t$ and estimate $G_{t+1}^R$. We refer to this approach as \texttt{HomoTemp}.
The algorithm gets as an input a DHIN graph $G$, the number of graph snapshots $t$, a target relation meta path $P(A,B)$, the latent space dimension $k$, and the link to predict $(a,b)$ at $t+1$. The algorithm first decomposes $G$ into a sequence of $t$ graphs $\{G_1, .., G_t\}$ (line 1) by considering the associated timestamps on edges. Next from each graph $G_i$, a corresponding augmented reduced graph $G^P_i$ is generated (lines 2-7) for which nodes are of type $a$ and $b$ (beginning and end of target relation meta path $P$). For example given $P(A,A)$=\textit{A--P--A}, each $G^P_i$ represents the co-authorship graph at time t. Finally the matrix factorization technique in \cite{Zhu2016} is applied (line 8) to infer latent spaces $Z_1, ...,Z_t$ and estimate $G^P_{t+1}$ by $Z_tZ_t^T$ (line 9). Note that $Z_\tau$ depends on $Z_{\tau-1}$ as used in the temporal regularization term in equation (\ref{latentOrigEqu}).



\begin{algorithm}[t]
\caption{Homogenize Link Prediction}\label{alg1}
\begin{algorithmic}[1]\scriptsize
\REQUIRE A DHIN graph $G$, the number of snapshots $t$, a target meta path $P(A,B)$, the latent space dimension $k$, the link to predict $(a,b)$ at $t+1$
%\ENSURE The predicted graph $G^P$ at time $t+1$ based on the target relation $P$
\ENSURE The probability of existence of link $(a,b)$ in $G^P_{t+1}$

\STATE $\{G_1, .., G_t\} \leftarrow DecomposeGraph(G, t)$

\FOR {each graph $G_i=(V_i,E_i)$}
    %\STATE $G^R_i \leftarrow AugmentedReducedGraph(G_i,P,S)$
    %\STATE Let $a$ and $b$ be the node types of beginning and end of $P$
    
    %\FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
    \FOR {each node $x \in V_i$ that $\phi(x)=A$}%of type $a$}
        \STATE Follow $P$ to reach a node $y\in V_i$ that $\phi(y)=B$%of type $b$ 
        \STATE Add nodes x and y, and edge $(x,y)$ to the augmented reduced graph $G_i^P$ 
\ENDFOR

\ENDFOR
%\STATE $G^R_{t+1} \leftarrow MF(G^R,k)$ \cite{Zhu2016}
%\STATE Infer temporal latent spaces $Z_1, .., Z_t$ using \textit{MF}%by optimizing Eq. \ref{latentReducedEqu}
\STATE $\{Z_1, .., Z_t\} \leftarrow MatrixFactorization(G^P_1, .., G^P_t, k)$

\STATE Return $Pr((a,b)\in E^P_{t+1}) \leftarrow \sum_{i=1}^{k} Z_t(a,i)\cdot Z_t(b,i)$


%\STATE $G^P_{t+1} \leftarrow Z_tZ^T_t$ 
%\STATE Return $G^P_{t+1}$
\end{algorithmic}
\end{algorithm}



\subsection{Meta path-based relationship prediction}

The above homogenize approach does not consider different semantics of meta paths between the source and destination nodes. In fact, Zhu et al. \cite{Zhu2016} assume that the probability of a link between nodes depends only on their latent positions. However, we also include meta path-based features in our prediction model. Our intuition is that along with latent space features leveraging meta path-based features, as in \cite{sun2011ASONAM}, helps to boost the prediction accuracy. In other word, we combine latent space features with topological meta path-based features. Sun et al. \cite{sun2011ASONAM} proposed a supervised learning framework, called \textit{PathPredict}, that uses the meta path-based features in a past time interval to predict the relationship building in a future time interval. Their model learns coefficients associated with each feature by maximizing the likelihood of new relationship formation.


We define a set of meta paths \cite{sun2011pathsim} on a given network schema and a target relation meta path $P$ to generate an augmented reduced graph (Definition \ref{def:ARG}) $G^P_i$ from $G_i$ based on $P$.  We then leverage the technique in \cite{Zhu2016} to predict $G^P_{t+1}$ given $G^P_1, ..., G^P_t$, by inferring the temporal latent space representation for nodes at time $t+1$.\amin{this para seems wrong!!!}


\begin{algorithm}[t]
\caption{Meta path-based Relationship Prediction}\label{alg2}
\begin{algorithmic}[1]\scriptsize
\REQUIRE A DHIN graph $G$, the number of snapshots $t$, a network schema $S$, a target meta path $P(A,B)$, the maximum length of a meta path $l$, the latent space dimension $k$, the link to predict $(a,b)$ at $t+1$
%\ENSURE The predicted graph $G^{P}$ at time $t+1$ based on the target relation $P$
\ENSURE The probability of existence of link $(a,b)$ in $G^P_{t+1}$

\STATE $\{G_1, .., G_t\} \leftarrow DecomposeGraph(G, t)$
%\STATE  $\{G^P_1, .., G^P_t\} \leftarrow BuildTargetAugmentedReducedGraph(G_1, .., G_t, P(a,b))$
\STATE  Generate target augmented reduced graphs $G^P_1, .., G^P_t$ following Algorithm 1 lines 2-7

\STATE $\{P_1, .., P_n\} \leftarrow GenerateMetaPaths(S, P(A,B), l)$

\FOR {each graph $G_i=(V_i,E_i)$}

    \FOR {each node $x \in V_i$ that $\phi(x)=A$}%of type $a$}
	\FOR {each meta path $P_j$}

        \STATE Follow $P_j$ to reach a node $y$ that $\phi(y)=B$%of type $b$}
        \STATE $w_{xy} \leftarrow Similarity(x,y, G_i)$
        \STATE Add nodes x and y, and edge $(x,y)$ with weight $w_{xy}$ to augmented reduced graph $G_i^{P_j}$ 
\ENDFOR

\ENDFOR

%\STATE $G^R_{t+1} \leftarrow MF(G^R,k)$ \cite{Zhu2016}
%\STATE Infer temporal latent spaces $Z_1, .., Z_t$ using \textit{MF}%by optimizing Eq. \ref{latentReducedEqu}
\STATE $\{Z_1, .., Z_t\} \leftarrow MatrixFactorization(G^{P_j}_1, .., G^{P_j}_t, k)$
\STATE $G^{P_j}_{t+1} \leftarrow Z_tZ^T_t$ 

\ENDFOR

\FOR {each pair $(x,y)$, where $x\in V^{P}_{t-1}$ and $y\in N(x)$ is a close neighbour of $x$ in $G^{P}_{t-1}$}

\STATE Add the feature vector $\langle G^{P_1}_{t-1}(x,y), G^{P_2}_{t-1}(x,y), ..., G^{P_n}_{t-1}(x,y)\rangle$ to the training set $T$ with label=1 if $(x,y) \in E^{P}_{t}$ otherwise label=0.

\ENDFOR

%\STATE $\forall (a,b\in N(a)) \in G^{P}_{t}$, add a feature vector to the training set with $w_{ab}$ in $G^{P_j}_{t-1}$ for each meta paths $P_j$, and label=1 if $(a,b) \in E^{P}_{t}$ otherwise label=0.

%\STATE Learn the model and apply it to the feature vector of $G^{P_j}_{t+1}$ with different meta path $P_j$.

\STATE $model \leftarrow Train(T)$
\STATE Return $Pr((a,b)\in E^P_{t+1}) \leftarrow Test(model, \langle G^{P_1}_{t}(a,b), G^{P_2}_{t}(a,b), ..., G^{P_n}_{t}(a,b)\rangle)$

%\STATE Build $G^{P}_{t+1}$ based on the cut-off values for the output of prediction model.
%\STATE Return $G^{P}_{t+1}$
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg2} gets as an input a DHIN graph $G$, the number of graph snapshots $t$, a network schema $S$, a target relation meta path $P(A,B)$ between node types $A$ and $B$, the maximum length of a meta path $l$, and the latent space dimension $k$. Same as Algorithm \ref{alg1}, it decomposes $G$ into a sequence of graphs (line 1). It then produces the set of all meta paths between nodes of type $A$ and type $B$ defined in the given target relation $P(A,B)$ (line 2). This is done by traversing the network schema $S$ (for instance through a BFS traversal) and generating meta paths with the maximum length of $l$. Next from each graph snapshot $G_i$, a corresponding augmented reduced graph $G^P_i$ is generated (lines 3-9) for which nodes are of type $A$ and $B$ (beginning and end of meta path $P$) and edges have weight based on a relation similarity measure, such as path count, between $A$ and $B$. Once the sequence of augmented reduced graphs \{$G^P_1, ..., G^P_t$\} are generated, we apply the matrix factorization technique in \cite{Zhu2016} to find a low rank $k$-dimensional latent space representation matrix $Z_\tau$ for nodes at time $\tau$.

% \begin{equation}\label{latentEqu}
%     \begin{array}{l}
% \argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G^{R_i}_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
% \\
% \text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
%     \end{array}
% \end{equation}




%* Restrict pathSim to 3-hops and not beyond

\subsubsection{The predictive model.} Given the training pairs of nodes and their corresponding meta path-based features (similarity weights $w$), we build a prediction model to learn the weights associated with these features by apply logistic regression. We define the probability of forming a \textit{new link in the future} from node $a$ to $b$ as $Pr(label=1|a, b; \boldsymbol{\theta}) = \frac{1}{e^{-z}+1}$, where $z=\sum\limits_{i=1}^{n}\theta_i.f_i(a,b)$ and $\theta_i$ is the associated weight for $n$ topological meta path-based features $f_i$ at current time between $a$ and $b$. We use logistic regression with $L_2$ regularization to estimate the optimal $\boldsymbol{\theta}$, given a training dataset with $l$ instance-label pairs, where $\alpha \sum_{j=1}^n \theta_j^2$ is the regularization term, and $C>0$ is a penalty parameter. 

%$\boldsymbol{\hat{\theta}} = 
%\operatorname*{arg\,max}_{\boldsymbol{\theta}}\sum_i log Pr(y_i = 1|a_i, b_i; \boldsymbol{\theta}) - \alpha \sum_{j=1}^N \theta_j^2
%$

\begin{equation}
\boldsymbol{\hat{\theta}} = 
\argmin\limits_{\boldsymbol{\theta}}C\sum_{i=1}^l -log Pr(label |a_i, b_i; \boldsymbol{\theta}) + \alpha \sum_{j=1}^n \theta_j^2
\end{equation}
  
In the testing phase, we predict a data point $x$ as positive if $\theta^Tx > 0$, and negative otherwise.


%We derive \textbf{$\hat{\theta}$} which which maximizes the likelihood of all the training pairs.

%We use maximum likelihood estimation in our experiments to derive which maximizes the likelihood of all the training pairs.

In the training phase, for each pair of nodes $(a,b)$ in $G^{P}_{t}$, where $b \in N(a)$, we add a feature vector $\boldsymbol{f}_t(a,b)$ to the training set with corresponding $w_{ab}$ in $G^{P_j}_{t-1}$ for each meta paths $P_j$, and with label=1 if $(a,b) \in E^{P}_{t}$ otherwise label=0. We then perform logistic regression to learn the model. Finally we apply the model to the feature vector of predicted graphs $G^{P_j}_{t+1}$ with different meta path $P_j$. Finally it builds $G^{P}_{t+1}$ based on the cut-off values for the output of prediction model.


\subsection{Combining latent and meta path-based features}


%Zhu et al. \cite{Zhu2016} studied the problem of temporal link prediction in the context of homogeneous networks, where the input is a sequence of graphs $G_1, ..., G_t$ and the output is the estimated $G_{t+1}$. The authors presented a matrix factorization with block-coordinate gradient descent (MF) 

Although the gradient descent algorithm used in the MF technique to infer latent space matrices in \cite{Zhu2016} is fast, we cannot apply it to meta paths efficiently since computing meta path values for all possible pairs of nodes is not scalable. Thus we restrict it only to those links that make new connections in the next time interval or negative samples and use logistic regression. 


\cite{Zhu2016} approximated $G_{ij}$ with $\sum_{l=1}^{k} Z_{il}Z_{jl}$ and \cite{sun2011pathsim} with $\sum_{l=1}^{n} \theta_l f_l(i,j)$


- $G_{ij} \approx  \sum_{l=1}^{n} \theta_l f_l(i,j) + \sum_{l=1}^{k} \beta_l Z_{il}Z_{jl}$



$ \argmin\limits_{Z} \sum\limits_{(i,j)\in O} \left \| G_\tau(i,j) - \Phi(z_{i}^Tz_{j} + \theta^Tf(i,j)) \right \|^2_F $

, where $\Phi$ and is the link function.

- Augmenting latent with explicit features helps to combine latent features with the results of any other link prediction model. Let $f(i,j)$ be the meta path feature between nodes $i$ and $j$. Then, we can learn latent features that fit the residual of $f$. In general the latent feature approach has a natural mechanism by which any predictive signal can be incorporated, whether it is an explicit feature vector or model predictions. Our hypothesis is that combining latent features with meta path-based features will improve performance on the test data. However, if the latent features learn similar structure to the meta path features, then combining the two may not be beneficial. We only consider the linear combination of latent and meta path features, however, these can be combined in different ways that is beyond the scope of this work.

\subsection{Implementation}

\amin{add system and OS spec}
We use the implementation of temporal latent space inference for a sequence of dynamic graph snapshots \footnote{\url{https://github.com/linhongseba/Temporal-Network-Embedding}}\cite{Zhu2016}.
% Self note: The hetrec-2011 dataset (MovieLense-IMDB) have missing user and movie ids as they only consider users with both rating and tags, thus we assign new ids to be able to use the TKDE code.
 For the classification part, we use the efficient LIBLINEAR \cite{fan2008liblinear} package\footnote{\url{https://github.com/cjlin1/liblinear}} and set the type of solver to L2-regularized logistic regression (primal). %that solves $min_w w^Tw/2 + C \sum log(1 + exp(-y_i w^Tx_i))$, where $w$ is the generated weight vector as the model for a given set of instance-label pairs $(x_i, y_i)$, $i$ = 1, . . . , l, $x_i \in R^n$, $y_i \in \{-1, +1\}$,  $w^Tw/2$ is the regularization term, and $C > 0$ is a penalty parameter. In the testing phase, we predict a data point $x$ as positive if $w^Tx > 0$, and negative otherwise.
We performed 5-fold cross validation for the training phase.



% https://arxiv.org/pdf/1803.00744.pdf

%We perform leave-one-patient-out testing, where all data belonging to a single patient are left out in a particular test fold. All hyper-parameters were chosen through a nested cross-validation performed on the training data alone. We used the area under the ROC curve (AUROC) metric to evaluate our classifiers. We use the method presented by DeLong et al. [27] to compute 95\% confidence intervals and to perform statistical significance tests to compare competing prediction methods (significance level was set at 5\%). All reported p values are based on a two-sided z-test.

%[27] DeLong, E.R., DeLong, D.M., Clarke-Pearson, D.L.: Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach. Biometrics (1988) 837?845






% \begin{algorithm}[h]
% \caption{Generate Predicted Graph}\label{alg1}
% \begin{algorithmic}[1]
% \REQUIRE A dynamic heterogeneous graph $G$, number of graph snapshots $t$, network schema $S$, target relation $R(a,b)$ between nodes of type $a$ and $b$, maximum length of a meta path $l$, latent space dimension $k$
% \ENSURE The predicted graph $G^R$ at time $t+1$ based on the given target relation $R$

% \STATE $\{G_1, .., G_t\} \leftarrow DecomposeGraph(G, t)$

% \STATE $\{P_1, .., P_n\} \leftarrow GenerateMetaPaths(S,R,l)$

% \FOR {each heterogeneous graph $G_i$}
%     %\STATE $G^R_i \leftarrow AugmentedReducedGraph(G_i,R,S)$
    
%     \FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
%     \FOR {each node $i$ of type $a$ in $G$}
%         \STATE follow $p$ to reach a node $j$ of type $b$ in $G$ 
%         \STATE $w_{ij} \leftarrow PathSim(i,j)$
%         \STATE add edge $(i,j)$ to graph $G^R$ with weight $w_{ij}$
%     \ENDFOR
% \ENDFOR

    
% \ENDFOR
% %\STATE $G^R_{t+1} \leftarrow MF(G^R,k)$ \cite{Zhu2016}
% \STATE Infer temporal latent spaces $Z_1, .., Z_t$ by optimizing Eq. \ref{latentEqu}

% \STATE $G^R_{t+1} \leftarrow Z_tZ^T_t$ 

% \STATE return $G^R_{t+1}$
% \end{algorithmic}
% \end{algorithm}


%The process of creating an augmented reduced graph is presented in Algorithm \ref{alg2}.

% \begin{algorithm}[h]
% \caption{Generate augmented reduced graph}\label{alg2}
% \begin{algorithmic}[1]
% \REQUIRE A heterogeneous graph $G$, target relation $R(a,b)$ between nodes of type $a$ and $b$, network schema $S$
% \ENSURE An augmented reduced graph $G^R$ based on the given target relation $R$

% \FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
%     \FOR {each node $i$ of type $a$ in $G$}
%         \STATE follow $p$ to reach a node $j$ of type $b$ in $G$ 
%         \STATE $w_{ij} \leftarrow PathSim(i,j)$
%         \STATE add edge $(i,j)$ to graph $G^R$ with weight $w_{ij}$
%     \ENDFOR
% \ENDFOR

% \STATE return $G^R$
% \end{algorithmic}
% \end{algorithm}