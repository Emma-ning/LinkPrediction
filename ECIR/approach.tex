\section{Proposed Relationship Prediction Approach}

Given a DHIN graph $G=(V,E)$, and the number of graph snapshots $t$ \amin{Ebrahim suggested "t subsequent graph snapshots" but I disagree!}, we first decompose $G$ to a sequence of $t$ HIN graphs ${G_1, .., G_t}$ based on links with associated timestamps. We then apply our techniques to predict relationships in $G_{t+1}$. As mentioned in Definition \ref{problemdef}, we intend to predict existence of a given type of relationship (target meta path) between two given nodes. Thus we define a new type of graph, called \textit{augmented reduced graph}, that is generated according to a given heterogeneous network and a target relation meta path. 

%\begin{definition}[Augmented reduced graph]\label{def:ARG}
%Given a HIN graph $G=(V,E)$ and a target meta path $\mathcal{P}(A_i,A_j)$ between nodes of type $A_i$ and $A_j$, an \textit{augmented reduced graph} $G^\mathcal{P}=(V^\mathcal{P},E^\mathcal{P})$ is a weighted graph, where $V^\mathcal{P} \subseteq V$ and nodes in $V^\mathcal{P}$ are of type $A_i$ and $A_j$, edges in $E^\mathcal{P}$ indicates relationships of type $\mathcal{P}$ in $G$, and each edge $e^\mathcal{P} = (u, v, w)$ is a weighted edge from a vertex $u$ to a vertex $v$ with a weight $w=Sim(u,v)$ indicating a similarity measure between $u$ and $v$. $\Box$
%\end{definition}

\begin{definition}[\textbf{Augmented reduced graph}]\label{def:ARG}
Given a HIN graph $G=(V,E)$ and a target meta path $\mathcal{P}(A_i,A_j)$ between nodes of type $A_i$ and $A_j$, an \textit{augmented reduced graph} $G^\mathcal{P}=(V^\mathcal{P},E^\mathcal{P})$ is a graph, where $V^\mathcal{P} \subseteq V$ and nodes in $V^\mathcal{P}$ are of type $A_i$ and $A_j$, and edges in $E^\mathcal{P}$ indicates relationships of type $\mathcal{P}$ in $G$. $\Box$
\end{definition}


For example, an augmented reduced graph for the network in Figure \ref{sampleNetwork} and target meta path $\mathcal{P}(A,A)$=\textit{A--P--V--P--A} is a graph whose nodes are of type \textit{Author} and whose edges represent \textit{publishing in the same venue}. %For example (\textit{Max}, \textit{Ada}) is an edge in the corresponding augmented reduced graph because they both published at KDD and ICDM. If we consider meta path $\mathcal{P}(A,A)$=\textit{A--P--A}, the augmented reduced graph represents a co-authorship graph, where nodes are of type \textit{Author} and edges, such as (\textit{Max}, \textit{Tom}), represent \textit{co-authorship}.

%\subsection{Algorithm}

\subsection{Homogenized link prediction}


\ebrahim{Right now, this part is written such that the reader gets a sense that we are only applying an existing method. Can you please rewrite this so that sense is not directly derived by the reader?}

Zhu et al. \cite{Zhu2016} studied the problem of temporal link prediction in the context of homogeneous networks where the input is a sequence of graphs $G_1, ..., G_t$ and the output is the estimated $G_{t+1}$. They present a matrix factorization (MF) with block-coordinate gradient descent which infers a low rank $k$-dimensional latent space matrix $Z_\tau$ for each adjacency matrix $G_\tau$ at time $\tau$ by minimizing 
\begin{equation}\label{latentOrigEqu}
    \begin{array}{l}
\argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
\\
\text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
    \end{array}
\end{equation}
where $\lambda$ is a regularization parameter, and  $(1-Z_{\tau}(u)Z_{\tau-1}(u)^T)$ penalizes node $u$ for suddenly changing its latent position. %Note that when computing the quadratic loss $\left \| G^R_\tau-Z_{\tau}BZ_{\tau}^T \right \|^2_F$, we ignore all of the diagonal entries.
$Z_\tau(u)$ is a row vector denoting $u$'s temporal latent space representation at time $\tau$, and $Z_\tau(u,i)$ indicates the position of $u$ in the $i$-th dimension at $Z$. The intuition behind their technique is that 1) nodes move smoothly in the latent space over time and it is less likely to have abrupt moves \cite{sarkar2005dynamic,zhang2014inferring}, and 2) user interactions are more likely to occur between similar users in a latent space representation. To predict adjacency matrix $G_{t+1}$, they used $Z_tZ_t^T$, however, they mentioned that $G_{t+1}$ can be formulated as $\Phi(f(Z_1,...Z_t))$, where $\Phi$ and $f$ are link and temporal functions that one may apply techniques such as nonparametric approaches \cite{Sarkar:2012} to learn them.

Algorithm \ref{alg1} is an adaptation of the above MF technique applied on a sequence of augmented reduced graphs $G^\mathcal{P}_i$ (Definition \ref{def:ARG}) given a target meta path $\mathcal{P}$, which changes Equation (\ref{latentOrigEqu}) by replacing $G_\tau$ with $G^\mathcal{P}_\tau$.
%to the following
%\begin{equation}\label{latentReducedEqu}
%    \begin{array}{l}
%\argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G^\mathcal{P}_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
%\\
%\text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
%    \end{array}
%\end{equation}
%Their MF technique \cite{Zhu2016} to infer $Z_t$ and estimate $G_{t+1}^R$. We refer to this approach as \texttt{HomoTemp}.
The algorithm gets as an input a DHIN graph $G$, the number of graph snapshots $t$, a target relation meta path $\mathcal{P}(A,B)$, the latent space dimension $k$, and the link to predict $(a,b)$ at $t+1$. The algorithm first decomposes $G$ into a sequence of $t$ graphs $G_1, .., G_t$ by considering the associated timestamps on edges (line 1). Next from each graph $G_i$, a corresponding augmented reduced graph $G^\mathcal{P}_i$ is generated (lines 2-7) for which nodes are of type $a$ and $b$ (beginning and end of target  meta path $\mathcal{P}$). For example given $\mathcal{P}(A,A)$=\textit{A--P--A}, each $G^\mathcal{P}_i$ represents the co-authorship graph at time t. Finally the matrix factorization technique in \cite{Zhu2016} is applied (line 8) to infer latent spaces $Z_1, ...,Z_t$ and estimate $G^\mathcal{P}_{t+1}$ by $Z_tZ_t^T$ (line 9). Note that $Z_\tau$ depends on $Z_{\tau-1}$ as used in the temporal regularization term in Equation (\ref{latentOrigEqu}).



\begin{algorithm}[t]
\caption{Homogenized Link Prediction}\label{alg1}
\begin{algorithmic}[1]%\scriptsize
\REQUIRE A DHIN graph $G$, the number of snapshots $t$, a target meta path $\mathcal{P}(A,B)$, the latent space dimension $k$, the link to predict $(a,b)$ at $t+1$
%\ENSURE The predicted graph $G^\mathcal{P}$ at time $t+1$ based on the target relation $\mathcal{P}$
\ENSURE The probability of existence of link $(a,b)$ in $G^\mathcal{P}_{t+1}$

\STATE $\{G_1, .., G_t\} \leftarrow DecomposeGraph(G, t)$

\FOR {each graph $G_i=(V_i,E_i)$}
    %\STATE $G^R_i \leftarrow AugmentedReducedGraph(G_i,P,S)$
    %\STATE Let $a$ and $b$ be the node types of beginning and end of $\mathcal{P}$
    
    %\FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
    \FOR {each node $x \in V_i$ that $\phi(x)=A$}%of type $a$}
        \STATE Follow $\mathcal{P}$ to reach a node $y\in V_i$ that $\phi(y)=B$%of type $b$ 
        \STATE Add nodes x and y, and edge $(x,y)$ to the augmented reduced graph $G_i^\mathcal{P}$ 
\ENDFOR

\ENDFOR
%\STATE $G^R_{t+1} \leftarrow MF(G^R,k)$ \cite{Zhu2016}
%\STATE Infer temporal latent spaces $Z_1, .., Z_t$ using \textit{MF}%by optimizing Eq. \ref{latentReducedEqu}
\STATE $\{Z_1, .., Z_t\} \leftarrow MatrixFactorization(G^\mathcal{P}_1, .., G^\mathcal{P}_t, k)$

\STATE Return $Pr((a,b)\in E^\mathcal{P}_{t+1}) \leftarrow \sum_{i=1}^{k} Z_t(a,i)Z_t(b,i)$


%\STATE $G^\mathcal{P}_{t+1} \leftarrow Z_tZ^T_t$ 
%\STATE Return $G^\mathcal{P}_{t+1}$
\end{algorithmic}
\end{algorithm}


\amin{Addressed Ebrahim comments till here!}


%\subsection{Meta path-based relationship prediction}
\subsection{Dynamic meta path-based relationship prediction}

The above homogenized approach does not consider different semantics of meta paths between the source and destination nodes. In fact, Zhu et al. \cite{Zhu2016} assume that the probability of a link between nodes depends only on their latent positions. On the other hand, Sun et al. \cite{sun2011ASONAM} proposed a supervised learning framework, called \textit{PathPredict}, that uses meta path-based features in a past time interval to predict the relationship building in a future time interval. It learns coefficients associated with features by maximizing the likelihood of new relationship formation. However, their model is learned based on one past interval and does not consider temporal changes as in \cite{Zhu2016}. Our intuition is that leveraging meta path-based features along with latent space features can help to boost the prediction accuracy. In other word, we combine latent space features with topological meta path-based features in our predictive model.


\begin{algorithm}[t]
\caption{Dynamic Meta path-based Relationship Prediction}\label{alg2}
\begin{algorithmic}[1]%\scriptsize
\REQUIRE A DHIN graph $G$, the number of snapshots $t$, a network schema $S$, a target meta path $\mathcal{P}(A,B)$, the maximum length of a meta path $l$, the latent space dimension $k$, the link to predict $(a,b)$ at $t+1$
%\ENSURE The predicted graph $G^\mathcal{P}$ at time $t+1$ based on the target relation $\mathcal{P}$
\ENSURE The probability of existence of link $(a,b)$ in $G^\mathcal{P}_{t+1}$

\STATE $\{G_1, .., G_t\} \leftarrow$ \textit{DecomposeGraph}$(G, t)$
%\STATE  $\{G^\mathcal{P}_1, .., G^\mathcal{P}_t\} \leftarrow BuildTargetAugmentedReducedGraph(G_1, .., G_t, \mathcal{P}(a,b))$
\STATE  Generate target augmented reduced graphs $G^\mathcal{P}_1, .., G^\mathcal{P}_t$ following Algorithm 1 lines 2-7

\STATE $\{\mathcal{P}_1, .., \mathcal{P}_n\} \leftarrow$ \textit{GenerateMetaPaths}$(S, \mathcal{P}(A,B), l)$

%\FOR {each graph $G_i=(V_i,E_i)$}
%
%    \FOR {each node $x \in V_i$ that $\phi(x)=A$}%of type $a$}
%	\FOR {each meta path $\mathcal{P}_j$}
%
%        \STATE Follow $\mathcal{P}_j$ to reach a node $y$ that $\phi(y)=B$%of type $b$}
%        \STATE $w_{xy} \leftarrow Similarity(x,y, G_i)$
%        \STATE Add nodes x and y, and edge $(x,y)$ with weight $w_{xy}$ to augmented reduced graph $G_i^{\mathcal{P}_j}$ 
%\ENDFOR
%\ENDFOR

%\STATE $\{Z_1, .., Z_t\} \leftarrow MatrixFactorization(G^{\mathcal{P}_j}_1, .., G^{\mathcal{P}_j}_t, k)$
%\STATE $G^{\mathcal{P}_j}_{t+1} \leftarrow Z_tZ^T_t$ 

%\ENDFOR

\STATE $\{Z_1, .., Z_t\} \leftarrow$ \textit{MatrixFactorization}$(G^\mathcal{P}_1, .., G^\mathcal{P}_t, k)$
\STATE $\hat{G}^\mathcal{P}_{t} \leftarrow Z_{t-1}Z^T_{t-1}$ and  $\hat{G}^\mathcal{P}_{t+1} \leftarrow Z_tZ^T_t$


\FOR {each pair $(x,y)$, where $x\in V^\mathcal{P}_{t-1}$ and $y\in N(x)$ is a nearby neighbor of $x$ in $G^\mathcal{P}_{t-1}$}

\STATE Add the feature vector $\langle$ $f^{\mathcal{P}_1}_{t-1}(x,y)$, $f^{\mathcal{P}_2}_{t-1}(x,y)$, ..., $f^{\mathcal{P}_n}_{t-1}(x,y)$, $\hat{G}^\mathcal{P}_{t}(x,y)\rangle$ to the training set $T$ with \textit{label}=1 if $(x,y)$ is a new link in $E^\mathcal{P}_{t}$ otherwise \textit{label}=0.

\ENDFOR

%\STATE $\forall (a,b\in N(a)) \in G^\mathcal{P}_{t}$, add a feature vector to the training set with $w_{ab}$ in $G^{\mathcal{P}_j}_{t-1}$ for each meta paths $\mathcal{P}_j$, and label=1 if $(a,b) \in E^\mathcal{P}_{t}$ otherwise label=0.

%\STATE Learn the model and apply it to the feature vector of $G^{\mathcal{P}_j}_{t+1}$ with different meta path $\mathcal{P}_j$.

\STATE $model \leftarrow$ \textit{Train}$(T)$
\STATE Return $Pr((a,b)\in E^\mathcal{P}_{t+1})$ $\leftarrow$ \textit{Test}($model$, $\langle$ $f^{\mathcal{P}_1}_{t}(a,b)$, $f^{\mathcal{P}_2}_{t}(a,b)$, ..., $f^{\mathcal{P}_n}_{t}(a,b)$, $\hat{G}^\mathcal{P}_{t+1}(a,b)\rangle)$

%\STATE Build $G^\mathcal{P}_{t+1}$ based on the cut-off values for the output of prediction model.
%\STATE Return $G^\mathcal{P}_{t+1}$
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg2} gets as input a DHIN graph $G$, the number of graph snapshots $t$, a network schema $S$, a target relation meta path $\mathcal{P}(A,B)$, the maximum length of a meta path $l$, the latent space dimension $k$, and the link to predict $(a,b)$ at $t+1$. Same as Algorithm \ref{alg1}, it decomposes $G$ into a sequence of graphs (line 1). Next it generates augmented reduced graphs $G^\mathcal{P}_i$s from $G_i$s based on $\mathcal{P}$ for which nodes are of type $A$ and $B$ (beginning and end of meta path $\mathcal{P}$) (line 2) as explained in Algorithm 1. It then produces the set of all meta paths between nodes of type $A$ and type $B$ defined in $\mathcal{P}(A,B)$ (line 3). This is done by traversing the network schema $S$ (for instance through a BFS traversal) and generating meta paths with the maximum length of $l$. It then applies the MF technique \cite{Zhu2016} to find latent space matrices $Z_i$ (line 4) and using them calculates the estimated augmented reduced graph $\hat{G}^\mathcal{P}$ at times $t$ and $t+1$ (line 5). The last steps are creating a training dataset with sample pairs $(x,y)$ with feature set containing $\hat{G}^\mathcal{P}_{t}(x,y)$, and meta path-based feature measures $f^{\mathcal{P}_i}_t(x,y)$ based on meta path $\mathcal{P}_i$ at time $t$, and \textit{label}=1 if $(x,y)$ is a new link in $G^\mathcal{P}_{t+1}$ otherwise \textit{label}=0 (lines 6-8), training the predictive model (line 9), generating features for the given pair $(a,b)$ and testing it using the trained model (line 10). In the following section we explain our learning technique in detail.

% \begin{equation}\label{latentEqu}
%     \begin{array}{l}
% \argmin\limits_{Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G^{R_i}_\tau-Z_{\tau}Z_{\tau}^T \right \|^2_F+\lambda \sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T) 
% \\
% \text{subject to :} \forall u,\tau,Z_{\tau}\geq 0, Z_{\tau}(u)Z_{\tau}(u)^T=1
%     \end{array}
% \end{equation}


%* Restrict pathSim to 3-hops and not beyond


%\begin{equation}\label{latentAndTopologicalEqu}
%    \begin{array}{l}
%\argmin\limits_{\boldsymbol{\theta},Z_1, .., Z_t}\sum\limits_{\tau=1}^{t}\left \| G_\tau - (Z_{\tau}Z_{\tau}^T + \sum\limits_{i=1}^{n}\theta_{i_\tau}\mathcal{F}_{i_\tau}) \right \|^2_F + \lambda (\sum\limits_{\tau=1}^{t}\sum\limits_{u}(1-Z_{\tau}(u)Z_{\tau-1}(u)^T)  + \sum\limits_{\tau=1}^{t} \sum\limits_{i=1}^{n} \theta_{i_\tau}^2)\\
%    \end{array}
%\end{equation}


%\subsubsection{The predictive model.}
\subsubsection{Combining latent and meta path-based features.}
Our hypothesis is that combining latent with topological features can increase the prediction accuracy as we can learn latent features that fit the residual of meta path-based features. However, if the latent features learn similar structure to the topological features, then mixing them may not be beneficial. One way to do so is by changing the loss function in Equation (\ref{latentOrigEqu}) to $\argmin\limits_{\boldsymbol{\theta_\tau},Z_\tau}\sum\limits_{\tau=1}^{t}\left \| G^\mathcal{P}_\tau - \Phi(Z_{\tau}Z_{\tau}^T + \sum\limits_{i=1}^{n}\theta_{i_{\tau-1}} \mathcal{F}^{\mathcal{P}_i}_{\tau-1}) \right \|^2_F$ and add another regularization term $\lambda \sum\limits_{\tau=1}^{t} \sum\limits_{i=1}^{n} \theta_{i_\tau}^2$, where $n$ is the number of meta path-based features, $\mathcal{F}^{\mathcal{P}_i}$ is the $i$-th meta path-based feature matrix defined on $G_i$, and $\theta_i$ is weights for feature $f_i$. Although the gradient descent algorithm used in the MF technique to infer latent space matrices in \cite{Zhu2016} is fast, it cannot be efficiently applied to the changed loss function. This is because it requires computing meta paths for all possible pairs of nodes in $\mathcal{F}^{\mathcal{P}_i}$ for all snapshots, which is not scalable as calculating similarity measures such as PathCount or PathSim can be very costly. For example computing path counts for \textit{A--P--V--P--A} meta path, can be done by multiply adjacency matrices $AP\times PV\times VP\times PA$. 


%Thus we restrict it only to those links that make new connections in the next time interval or negative samples and use logistic regression.
As an alternative solution we build a predictive model that considers a linear combination of topological and latent features. These features, however, can be combined in different ways that is beyond the scope of this work. Given the training pairs of nodes and their corresponding meta path-based and latent features, we apply logistic regression to learn the weights associated with these features. We define the probability of forming a \textit{new link} in future from node $a$ to $b$ as %$Pr(label=1|a, b; \boldsymbol{\theta}) = \frac{1}{e^{-z}+1}$, where $z=\sum\limits_{i=1}^{n}\theta_i.f_i(a,b)$ 
 $Pr(label=1|a, b; \boldsymbol{\theta}) = \frac{1}{e^{-z}+1}$, where $z=\sum\limits_{i=1}^{n}\theta_i f^{\mathcal{P}_i}(a,b) + \sum\limits_{j=1}^{k} \theta_{n+j}Z(a,j)Z(b,j)$, and $\theta_1,\theta_2,..., \theta_n$ and $\theta_{n+1},\theta_{n+2},..., \theta_{n+k}$ are associated weights for meta path-based features and latent features at current time between $a$ and $b$. Given a training dataset with $l$ instance-label pairs, we use logistic regression with $L_2$ regularization to estimate the optimal $\boldsymbol{\theta}$ as%where $\lambda \sum_{j=1}^{n+k} \theta_j^2$ is the regularization term, and $C>0$ is a penalty parameter. 

%$\boldsymbol{\hat{\theta}} = 
%\operatorname*{arg\,max}_{\boldsymbol{\theta}}\sum_i log Pr(y_i = 1|a_i, b_i; \boldsymbol{\theta}) - \alpha \sum_{j=1}^N \theta_j^2
%$

\begin{equation}
\boldsymbol{\hat{\theta}} = 
\argmin\limits_{\boldsymbol{\theta}}\sum_{i=1}^l -log Pr(label |a_i, b_i; \boldsymbol{\theta}) + \lambda \sum_{j=1}^{n+k} \theta_j^2
\end{equation}
 
We preferred combining features in this learning framework since $G_i$ is very sparse and thus the number of newly formed links are much less compared to all possible links. Consequently calculating meta path-based features for training dataset is scalable compared to the MF technique. Moreover, similar to \cite{sun2011ASONAM}, in order to avoid excessive computing of meta path-based measures between nodes that might not be related, we confine samples to pairs that are located in a nearby neighborhood. More specifically, for each source node $x$ in $G^\mathcal{P}_{i}$, we choose target nodes that are within 3-hop of $x$ but not in 1-hop, i.e, are not connected to $x$ in $G^\mathcal{P}_{i}$. We first find all target nodes that make a new relationship with $x$  in $G^\mathcal{P}_{i+1}$ and label respective samples as positive. Next we sample an equal number of negative pairs, i.e., those targets that do not make new connection, to balance our training set. Once the dataset is built, we perform logistic regression to learn the model and then apply the predictive model to the feature vector  $\langle f^{\mathcal{P}_1}_{t}(a,b), f^{\mathcal{P}_2}_{t}(a,b), ..., f^{\mathcal{P}_n}_{t}(a,b), \hat{G}^\mathcal{P}_{t+1}(a,b)\rangle$. The output probability can be later interpreted as a binary value based on a user defined cut-off.

%In the testing phase, we predict a data point $x$ as positive if $\theta^Tx > 0$, and negative otherwise.

%We derive \textbf{$\hat{\theta}$} which which maximizes the likelihood of all the training pairs.

%\cite{Zhu2016} approximated $G_{ij}$ with $\sum_{l=1}^{k} Z_{il}Z_{jl}$ and \cite{sun2011pathsim} with $\sum_{l=1}^{n} \theta_l f_l(i,j)$
%- $G_{ij} \approx  \sum_{l=1}^{n} \theta_l f_l(i,j) + \sum_{l=1}^{k} \beta_l Z_{il}Z_{jl}$
%$ \argmin\limits_{Z} \sum\limits_{(i,j)\in O} \left \| G_\tau(i,j) - \Phi(z_{i}^Tz_{j} + \theta^Tf_\tau(i,j)) \right \|^2_F $



\subsection{Implementation}

\amin{add system and OS spec}
We use the implementation of temporal latent space inference for a sequence of dynamic graph snapshots \footnote{\url{https://github.com/linhongseba/Temporal-Network-Embedding}}\cite{Zhu2016}.
% Self note: The hetrec-2011 dataset (MovieLense-IMDB) have missing user and movie ids as they only consider users with both rating and tags, thus we assign new ids to be able to use the TKDE code.
 For the classification part, we use the efficient LIBLINEAR \cite{fan2008liblinear} package\footnote{\url{https://github.com/cjlin1/liblinear}} and set the type of solver to L2-regularized logistic regression (primal). %that solves $min_w w^Tw/2 + C \sum log(1 + exp(-y_i w^Tx_i))$, where $w$ is the generated weight vector as the model for a given set of instance-label pairs $(x_i, y_i)$, $i$ = 1, . . . , l, $x_i \in R^n$, $y_i \in \{-1, +1\}$,  $w^Tw/2$ is the regularization term, and $C > 0$ is a penalty parameter. In the testing phase, we predict a data point $x$ as positive if $w^Tx > 0$, and negative otherwise.
We performed 5-fold cross validation for the training phase.



% https://arxiv.org/pdf/1803.00744.pdf

%We perform leave-one-patient-out testing, where all data belonging to a single patient are left out in a particular test fold. All hyper-parameters were chosen through a nested cross-validation performed on the training data alone. We used the area under the ROC curve (AUROC) metric to evaluate our classifiers. We use the method presented by DeLong et al. [27] to compute 95\% confidence intervals and to perform statistical significance tests to compare competing prediction methods (significance level was set at 5\%). All reported p values are based on a two-sided z-test.

%[27] DeLong, E.R., DeLong, D.M., Clarke-Pearson, D.L.: Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach. Biometrics (1988) 837?845






% \begin{algorithm}[h]
% \caption{Generate Predicted Graph}\label{alg1}
% \begin{algorithmic}[1]
% \REQUIRE A dynamic heterogeneous graph $G$, number of graph snapshots $t$, network schema $S$, target relation $R(a,b)$ between nodes of type $a$ and $b$, maximum length of a meta path $l$, latent space dimension $k$
% \ENSURE The predicted graph $G^R$ at time $t+1$ based on the given target relation $R$

% \STATE $\{G_1, .., G_t\} \leftarrow DecomposeGraph(G, t)$

% \STATE $\{\mathcal{P}_1, .., \mathcal{P}_n\} \leftarrow GenerateMetaPaths(S,R,l)$

% \FOR {each heterogeneous graph $G_i$}
%     %\STATE $G^R_i \leftarrow AugmentedReducedGraph(G_i,R,S)$
    
%     \FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
%     \FOR {each node $i$ of type $a$ in $G$}
%         \STATE follow $p$ to reach a node $j$ of type $b$ in $G$ 
%         \STATE $w_{ij} \leftarrow PathSim(i,j)$
%         \STATE add edge $(i,j)$ to graph $G^R$ with weight $w_{ij}$
%     \ENDFOR
% \ENDFOR

    
% \ENDFOR
% %\STATE $G^R_{t+1} \leftarrow MF(G^R,k)$ \cite{Zhu2016}
% \STATE Infer temporal latent spaces $Z_1, .., Z_t$ by optimizing Eq. \ref{latentEqu}

% \STATE $G^R_{t+1} \leftarrow Z_tZ^T_t$ 

% \STATE return $G^R_{t+1}$
% \end{algorithmic}
% \end{algorithm}


%The process of creating an augmented reduced graph is presented in Algorithm \ref{alg2}.

% \begin{algorithm}[h]
% \caption{Generate augmented reduced graph}\label{alg2}
% \begin{algorithmic}[1]
% \REQUIRE A heterogeneous graph $G$, target relation $R(a,b)$ between nodes of type $a$ and $b$, network schema $S$
% \ENSURE An augmented reduced graph $G^R$ based on the given target relation $R$

% \FOR {each path $p$ between nodes of type $a$ and $b$ in $S$}
%     \FOR {each node $i$ of type $a$ in $G$}
%         \STATE follow $p$ to reach a node $j$ of type $b$ in $G$ 
%         \STATE $w_{ij} \leftarrow PathSim(i,j)$
%         \STATE add edge $(i,j)$ to graph $G^R$ with weight $w_{ij}$
%     \ENDFOR
% \ENDFOR

% \STATE return $G^R$
% \end{algorithmic}
% \end{algorithm}